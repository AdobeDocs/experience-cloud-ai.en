---
title: Experimentation Agent
description: Learn how to use Experimentation Agent
---
# Experimentation Agent

>[!AVAILABILITY]
>
>The Experimentation Agent is available to all customers who have purchased the paid license of Journey Optimizer Experimentation Accelerator and integrates seamlessly with either Adobe Target or Adobe Journey Optimizer.
>
>[Learn more on Journey Optimizer Experimentation Accelerator](https://experienceleague.adobe.com/en/docs/experimentation-accelerator/using/overview)

## Overview  

The **Experimentation Agent** is an AI-powered tool that modernizes how you can run and manage digital experiments across websites, emails, push messages, and applications. Built on Adobe Experience Platform AI platform and experimentation tools, the **Experimentation Agent** helps you run experiments more efficiently, organize business goals, and generate actionable insights, highlighting what worked, what did not, and where to experiment next.

The following permissions in order to fully use the Experimentation Agent features.

* **View Experiments**: This permission lets you use the Experimentation Agent to view insights into the experiment directly in AI Assistant.

* **Manage Experiment Metada**: This permission lets you use the Experimentation Agent to create new experiments directly in AI Assistant.

➡️ [Learn more in Journey Optimizer Experimentation Accelerator documentation](https://experienceleague.adobe.com/en/docs/experimentation-accelerator/using/get-started/experiment-accelerator-access)

As part of Experimentation Accelerator feature, the Agent delivers:

* **Performance**: a clear view of what happened in the experiment

* **Insights**: an explanation of why the results occurred

* **Opportunities**: guidance on the next actions to take

![Sample for Experimentation Agent](./images/experiment/experiment-agent.png)

## Use Cases    

The Experimentation Agent enhances each phase of the experimentation workflow by analyzing results, interpreting content, and suggesting next steps. 

Its capabilities can be grouped into five key functions:

* **Experiment Summarization**

    Provide a clear, non-technical overview of experiment results for stakeholders.
    
* **Content Analysis**

    Examine the messaging or creative elements of treatments to understand why certain ones outperformed others.

* **Attribute Identification**    

    Categorize treatments by their key attributes, e.g., themes, tones, formats, and connect those attributes to conversion outcomes.

* **Recommendation Generation**    

    Suggest new treatments or adjustments to test, based on insights from prior experiments.

* **Opportunities**

    Identify broader areas or new angles for experimentation to uncover untapped potential.

## In Scope and Out of Scope Features

### **In Scope**

The following capabilities are currently supported:

* Performance
* Insights
* Opportunities

### **Out of Scope**

The following functionalities are currently not supported:

* Creating or editing experiments
* Using multiple metrics for reporting use cases

## Sample Prompts

Here is a list of prompt samples to help you get started with the Experimentation Agent:

### General questions

|Prompts|
|-|
|What experiments are running?|
|Which experiments are running for the `<campaign name>`?|
|What experiments started in the last month?|
|How many experiments ended in the past year? |
|Which experiments are currently paused/stopped/etc? |
|What common patterns are emerging from recent tests?|
|What is the average duration of experiments in the last quarter?|

### Performance questions

|Prompts|
|-|
|For my `<experiment name>`, what treatment is leading?|
|What is the lift of the `<experiment name>`?|
|Which experiments had statistically significant results?|
|Which experiments had the best conversion rate?|

### Insights questions

|Prompts|
|-|
|What is `<experiment name>` testing? ?|
|What did we learn from the `<experiment name>`?|
|Can you tell me why treatment A won?|
|What themes are trending in winning variants?|
|What common patterns are emerging from recent tests?|
|Did anything unexpected happen in `<experiment name>`?|

### Opportunities questions

|Prompts|
|-|
|What do you recommend I do next after this experiment?|
|Is the any way to improve `<experiment name>`?|
|What opportunities became clearer after `<experiment name>`?|
|What could I test next to prove the hypothesis from `<experiment name>`?|
|What additional use cases should I implement?|
